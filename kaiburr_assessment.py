# -*- coding: utf-8 -*-
"""Kaiburr - Assessment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IY4yKJ61a9m6iyVlrqKMDJzCXt_lsZZ7

# **Perform a Multi-Text Classification on consumer complaint dataset**



# **Import packages**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

"""# **Importing the dataset through url using pandas**"""

import pandas as pd
url='https://files.consumerfinance.gov/ccdb/complaints.csv'
data = pd.read_csv(url) # use sep="," for coma separation. 
data.head()

"""# **Exploratory Data Analysis (EDA) and Feature Engineering**
# **By info we trying to find the datatypes of all columns present in dataset** 
"""

data.info()

"""**shape is used to find total no. of rows and columns present (row,column)**"""

data.shape

"""**isnull().sum() is used to find the sum of null values present**"""

data.isnull().sum()

data['Product'].value_counts()

"""**<!-- Replacing the features inside the columns features -->**

# **Replacing the columnn features**
"""

data.replace({'Product': 
             {'Credit reporting, credit repair services, or other personal consumer reports': 
              'Credit reporting, repair, or other', 
              'Credit reporting': 'Credit reporting, repair, or other',
             'Credit card': 'Credit card or prepaid card'
             }}, 
            inplace= True)

df=data[(data['Product'] =='Mortgage') | (data['Product'] =='Debt collection') | (data['Product'] =='Consumer Loan') | (data['Product'] =='Credit reporting, repair, or other')]

df.head()

# 0 Credit reporting, repair, or
# other
# 1 Debt collection
# 2 Consumer Loan
# 3 Mortgage

df.shape

"""**The dataset contains features that are not necessary to solve our multi-classification problem. For this text classification problem, we are going to build another dataframe that contains ‘Product’ and ‘Consumer complaint narrative’ (renamed as 'Consumer_complaint')**"""

# Create a new dataframe with two columns
df1 = df[['Product', 'Consumer complaint narrative']].copy()

# Remove missing values (NaN)
df1 = df1[pd.notnull(df1['Consumer complaint narrative'])]

# Renaming second column for a simpler name
df1.columns = ['Product', 'Consumer_complaint'] 

df1.shape

df1.head()

"""## **Out of 100 what percent of complaints are registered **"""

total = df1['Consumer_complaint'].notnull().sum()
round((total/len(df)*100),1)

"""**Graphical representation of product category vs complaints**"""

fig = plt.figure(figsize=(8,6))
colors = ['darkblue','orange','green','red']
df1.groupby('Product').Consumer_complaint.count().sort_values().plot.barh(
    ylim=0, color=colors, title= 'NUMBER OF COMPLAINTS IN EACH PRODUCT CATEGORY\n')
plt.xlabel('Number of ocurrences', fontsize = 10);

df['Consumer disputed?'].value_counts()

pd.crosstab(df['Product'],df['Consumer disputed?']).plot(kind='bar')

df=df.drop('Complaint ID',axis=1)

sns.countplot(x='Timely response?',data=df)

df['State'].value_counts()

"""**pie chart represenation of Florida state vs Issues filed by the consumer**"""

df[df['State']=='FL']['Issue'].value_counts().head(5).plot.pie(explode=[0.2,0,0,0,0],shadow=True)
# Unsquish the pie.
import matplotlib.pyplot as plt
plt.gca().set_aspect('equal')

import plotly.offline as py
import plotly.graph_objs as go
from plotly.offline import iplot
p_product_discussions = round(df["Product"].value_counts() / len(df["Product"]) * 100,2)

print(p_product_discussions)

labels = list(p_product_discussions.index)
values = p_product_discussions.values.tolist()
colors = ['#F78181', '#F5A9BC', '#2E9AFE', '#58FA58', '#FAAC58', '#088A85', '#8A0808', '#848484', '#F781F3', '#D7DF01', '#2E2EFE']


product_pie = go.Pie(labels=labels, values=values, 
                          marker=dict(colors=colors,
                         line=dict(color='#000000', width=2)))

layout = go.Layout(title='Product Types')

fig = go.Figure(data=[product_pie], layout=layout)
iplot(fig)

"""** Bases on chart depiction,most of the consumer's problem are on credit reporting,repairt and other with 82.7%**"""

df1.head()

"""**using hashmap converting the columns features of Produc into values for prediction**"""

df1['category_id'] = df1['Product'].factorize()[0]
from io import StringIO
category_id_df1 = df1[['Product', 'category_id']].drop_duplicates().sort_values('category_id')
category_to_id = dict(category_id_df1.values)
id_to_category = dict(category_id_df1[['category_id', 'Product']].values)

category_to_id

"""## **For early prediction from the original dataset picking up 500 samples.**"""

df2 = df1.sample(2000, random_state=1).copy()

df2.shape

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import chi2
from IPython.display import display
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn import metrics

"""# **TfidfTransformer(term frequency and inverse document frequency):TF-IDF will transform the text into meaningful representation of integers or numbers which is used to fit machine learning algorithm for predictions.**

"""

tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,
                        ngram_range=(1, 2), 
                        stop_words='english')

# We transform each complaint into a vector
features = tfidf.fit_transform(df2.Consumer_complaint).toarray()

labels = df2.category_id

print("Each of the %d complaints is represented by %d features (TF-IDF score of unigrams and bigrams)" %(features.shape))

"""# **Splitting the dataset into training and target variable**"""

X = df2['Consumer_complaint'] # Collection of documents
y = df2['Product'] # Target or the labels we want to predict

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size=0.25,
                                                    random_state = 0)

"""# **Multi-Classification models**
# **The classification models evaluated are:**

Random Forest

Linear Support Vector Machine

Multinomial Naive Bayes

Logistic Regression.
"""

models = [
    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),
    LinearSVC(),
    MultinomialNB(),
    LogisticRegression(random_state=0),
]

# 5 Cross-validation
CV = 5
cv_df = pd.DataFrame(index=range(CV * len(models)))

entries = []
for model in models:
  model_name = model.__class__.__name__
  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)
  for fold_idx, accuracy in enumerate(accuracies):
    entries.append((model_name, fold_idx, accuracy))
    
cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])
cv_df

"""# **Comparison of model performance**"""

mean_accuracy = cv_df.groupby('model_name').accuracy.mean()
std_accuracy = cv_df.groupby('model_name').accuracy.std()

acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, 
          ignore_index=True)
acc.columns = ['Mean Accuracy', 'Standard deviation']
acc

"""**Out of 4 models algorithm linearSVC is best with accuracy of 87.6%**

# **Model Evaluation**
"""

X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(features, 
                                                               labels, 
                                                               df2.index, test_size=0.25)
model = LinearSVC()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

"""# **Precision is a measure of how many of the positive predictions made are correct (true positives)**
# **Recall is a measure of how many of the positive cases the classifier correctly predicted, over all the positive cases in the data**
# **F1-Score is a measure combining both precision and recall(harmonc Mean)**
"""

y_pred

df2['Product'].value_counts()

# print('t\t\t\t CLASSIFICATIION METRICS\n')
print(metrics.classification_report(y_test, y_pred, 
                                    target_names= df2['Product'].unique()))

conf_mat = confusion_matrix(y_test, y_pred)

"""# **Prediction**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size=0.25,
                                                    random_state = 0)

tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,
                        ngram_range=(1, 2), 
                        stop_words='english')

fitted_vectorizer = tfidf.fit(X_train)
tfidf_vectorizer_vectors = fitted_vectorizer.transform(X_train)

model = LinearSVC().fit(tfidf_vectorizer_vectors, y_train)

# df2['Consumer_complaint'].values

new_complaint = """I contacted Transunion Credit agency to get my credit score. I tried online at the website and tried calling. I spoke with representative and said I would Ike to know what my credit score is. I was told I would have to pay for a membership. I explained to representative that I can go online to XXXX  and XXXX  and look at my credit score instantly. Why does Transunion charge a person a fee to get information on their owe credit? So I would like this to be investigated. Transunion should not be making money off of one 's own information."""

print(model.predict(fitted_vectorizer.transform([new_complaint])))
df1[df1['Consumer_complaint'] == new_complaint]